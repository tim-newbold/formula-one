{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "mlANEWbjoVc7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8Divhdxg37g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "139049a6-833c-40de-f9c5-87c723d9a3d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/MyDrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/MyDrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing my libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from xgboost import XGBRegressor, plot_tree, plot_importance\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import requests"
      ],
      "metadata": {
        "id": "WXWYY14Gg9cE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import training data\n",
        "df = pd.read_csv('/content/MyDrive/MyDrive/F1/f1_full_v3.csv')\n",
        "\n",
        "# import testing data\n",
        "test_data = pd.read_csv('/content/MyDrive/MyDrive/F1/predict.csv')"
      ],
      "metadata": {
        "id": "elfFC6AFhEY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# copying the data frame for the model\n",
        "xgb2 = df.copy()"
      ],
      "metadata": {
        "id": "y2Yw6V_Qpgkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "plpxIyLAoTKs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialization"
      ],
      "metadata": {
        "id": "jdvo4neSopaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Columns to drop\n",
        "cols_to_drop = ['driverid', 'driver', 'name', 'race_year', 'url']\n",
        "\n",
        "# Drop the unwanted columns\n",
        "xgb2.drop(columns=cols_to_drop, inplace = True)\n",
        "\n",
        "# encode categorical columns\n",
        "categorical_cols = ['circuit_type', 'direction', 'overtake_rating', 'track_type']\n",
        "xgb2 = pd.get_dummies(xgb2, columns=categorical_cols, drop_first=True)"
      ],
      "metadata": {
        "id": "HVrgbKuOoZQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setup the testing and training split\n",
        "# Define the target variable and the features\n",
        "y = xgb2['position']\n",
        "X = xgb2.drop(columns=['position'])\n",
        "\n",
        "# Split the data into training and test sets (80% training, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "RBa6N94goiEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimization"
      ],
      "metadata": {
        "id": "u5jw_Lgyon3r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypertuning best params"
      ],
      "metadata": {
        "id": "xLl_PNRAosQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define an expanded parameter distribution for XGBoost\n",
        "param_distributions = {\n",
        "    'learning_rate': [0.01, 0.03, 0.05, 0.1, 0.2],\n",
        "    'max_depth': [3, 4, 5, 6, 7, 8],\n",
        "    'min_child_weight': [1, 2, 3, 4, 5],\n",
        "    'gamma': [0, 0.01, 0.1, 0.2, 0.3],              # Minimum loss reduction required to make a split\n",
        "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],    # Fraction of features used per tree\n",
        "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],           # Fraction of samples used per tree\n",
        "    'n_estimators': [100, 200, 300, 500],             # Number of trees\n",
        "    'reg_alpha': [0, 0.01, 0.1, 1, 10],               # L1 regularization\n",
        "    'reg_lambda': [1, 1.5, 2, 3, 5]                   # L2 regularization\n",
        "}\n",
        "\n",
        "# Initialize the XGBoost regressor with categorical support and the histogram tree method\n",
        "xgb_model = XGBRegressor(enable_categorical=True, tree_method='hist')\n",
        "\n",
        "# Setup RandomizedSearchCV:\n",
        "# n_iter defines how many parameter settings are randomly sampled.\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=xgb_model,\n",
        "    param_distributions=param_distributions,\n",
        "    n_iter=100,                 # Increase iterations to explore the expanded search space\n",
        "    cv=5,\n",
        "    scoring='neg_mean_absolute_error',\n",
        "    n_jobs=-1,\n",
        "    verbose=2,\n",
        "    random_state=42             # For reproducibility\n",
        ")\n",
        "\n",
        "# Assuming X_train and y_train are already defined from your train-test split:\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Retrieve the best parameters and best score\n",
        "best_params = random_search.best_params_\n",
        "best_score = random_search.best_score_\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(\"Best CV Score (neg_mean_absolute_error):\", best_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h83xHlYIomph",
        "outputId": "6598c9d9-8802-4d99-da52-7f35c37f204e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
            "Best Parameters: {'subsample': 0.8, 'reg_lambda': 3, 'reg_alpha': 10, 'n_estimators': 500, 'min_child_weight': 4, 'max_depth': 6, 'learning_rate': 0.05, 'gamma': 0.01, 'colsample_bytree': 0.7}\n",
            "Best CV Score (neg_mean_absolute_error): -1.6968443632125854\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Model with best params"
      ],
      "metadata": {
        "id": "5vz4v7yeoyxs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define static parameters for XGBoost\n",
        "params = {\n",
        "  'subsample': 0.8,\n",
        "  'reg_lambda': 3,\n",
        "  'reg_alpha': 10,\n",
        "  'n_estimators': 500,\n",
        "  'min_child_weight': 4,\n",
        "  'max_depth': 6,\n",
        "  'learning_rate': 0.05,\n",
        "  'gamma': 0.01,\n",
        "  'colsample_bytree': 0.7}\n",
        "\n",
        "# Initialize the XGBoost regressor with the static hyperparameters\n",
        "xgb_model = XGBRegressor(\n",
        "    enable_categorical=True,\n",
        "    tree_method='hist',\n",
        "    colsample_bytree=params['colsample_bytree'],\n",
        "    learning_rate=params['learning_rate'],\n",
        "    max_depth=params['max_depth'],\n",
        "    min_child_weight=params['min_child_weight'],\n",
        "    n_estimators=params['n_estimators'],\n",
        "    subsample=params['subsample'])\n",
        "\n",
        "\n",
        "# Train the model\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = xgb_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = mse ** 0.5\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"Mean Absolute Error (MAE):\", mae)\n",
        "print(\"Mean Squared Error (MSE):\", mse)\n",
        "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
        "print(\"R-squared Score:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlT5H8yXo0vy",
        "outputId": "d8de67e9-3b89-4969-b273-75b14dc46f7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error (MAE): 1.7657370567321777\n",
            "Mean Squared Error (MSE): 5.314754486083984\n",
            "Root Mean Squared Error (RMSE): 2.305375129145794\n",
            "R-squared Score: 0.8122528195381165\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature importance"
      ],
      "metadata": {
        "id": "jXhm8dsepDsP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot feature importance using XGBoost's built-in function\n",
        "plt.figure(figsize=(10, 8))\n",
        "plot_importance(xgb_model)\n",
        "plt.title(\"Feature Importances\")\n",
        "plt.show()\n",
        "\n",
        "importances = xgb_model.feature_importances_\n",
        "features = X.columns\n",
        "\n",
        "# Sort features by importance (highest first)\n",
        "sorted_features = sorted(zip(features, importances), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "print(\"Sorted Feature Importances:\")\n",
        "for feature, importance in sorted_features:\n",
        "    print(f\"{feature}: {importance}\")"
      ],
      "metadata": {
        "id": "3bEhIQRopFlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing Model"
      ],
      "metadata": {
        "id": "qJim7KzjpJmO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep the driver information in a separate DataFrame or Series\n",
        "drivers = test_data['driver']\n",
        "\n",
        "# Assuming you previously dropped 'driver' before training the model\n",
        "X_test = test_data.drop(columns=['driver'])\n",
        "\n",
        "# Check if the 'finish' column is present and needs to be dropped for prediction\n",
        "if 'finish' in X_test.columns:\n",
        "    X_test = X_test.drop(columns='finish')\n",
        "\n",
        "# Reset the column ordering\n",
        "X_test = X_test[X.columns]\n",
        "\n",
        "# Predict using the trained model\n",
        "predictions = xgb_model.predict(X_test)\n",
        "\n",
        "# Combine the driver information with the predictions\n",
        "results = pd.DataFrame({\n",
        "    'Driver': drivers,\n",
        "    'Predicted_Finish': predictions\n",
        "})\n",
        "\n",
        "# Sort the DataFrame by the 'Predicted_Finish' column in ascending order\n",
        "results_sorted = results.sort_values(by='Predicted_Finish', ascending=True)\n",
        "\n",
        "# Print the sorted DataFrame\n",
        "print(results_sorted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELr5nbpUpH-f",
        "outputId": "b9dc3730-755e-4265-f8e1-a19e48f87049"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " columns: ['grid', 'laps', 'length', 'turns', 'drs_zones', 'pit_stops', 'laps_led', 'is_verstappen', 'driver_rank', 'constructor_rank', 'average_speed', 'track_df', 'is_wet', 'traction', 'grip', 'abrasion', 'evolution', 'stress', 'braking', 'lateral', 'downforce', 'lap_down', 'dnf', 'circuit_type_1', 'circuit_type_2', 'circuit_type_3', 'circuit_type_4', 'direction_1', 'overtake_rating_2', 'overtake_rating_3', 'overtake_rating_4', 'track_type_Semi-Permanent', 'track_type_Street Circuit']\n",
            " columns: ['grid', 'laps', 'length', 'turns', 'drs_zones', 'pit_stops', 'laps_led', 'is_verstappen', 'driver_rank', 'constructor_rank', 'average_speed', 'track_df', 'is_wet', 'traction', 'grip', 'abrasion', 'evolution', 'stress', 'braking', 'lateral', 'downforce', 'lap_down', 'dnf', 'circuit_type_1', 'circuit_type_2', 'circuit_type_3', 'circuit_type_4', 'direction_1', 'overtake_rating_2', 'overtake_rating_3', 'overtake_rating_4', 'track_type_Semi-Permanent', 'track_type_Street Circuit']\n",
            "                   Driver  Predicted_Finish\n",
            "11           Lando Norris          2.382492\n",
            "17          Oscar Piastri          2.579882\n",
            "14         Max Verstappen          2.595120\n",
            "7          George Russell          2.995457\n",
            "12         Lewis Hamilton          3.162795\n",
            "3         Charles Leclerc          3.602844\n",
            "1   Andrea Kimi Antonelli          6.069554\n",
            "19           Yuki Tsunoda          7.758960\n",
            "0         Alexander Albon          8.089579\n",
            "5         Fernando Alonso          9.140270\n",
            "8            Isack Hadjar          9.208580\n",
            "2            Carlos Sainz          9.645828\n",
            "18           Pierre Gasly         10.550732\n",
            "10           Lance Stroll         10.743402\n",
            "4            Esteban Ocon         10.858278\n",
            "15        Nico Hulkenberg         10.881378\n",
            "13            Liam Lawson         10.971525\n",
            "9             Jack Doohan         12.442229\n",
            "16         Oliver Bearman         12.581966\n",
            "6       Gabriel Bortoleto         13.525088\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Storage"
      ],
      "metadata": {
        "id": "YUyaxjE_tu6V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Alternate Params"
      ],
      "metadata": {
        "id": "Za9uxypStwM7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'subsample': 0.6, 'reg_lambda': 3, 'reg_alpha': 0, 'n_estimators': 500, 'min_child_weight': 5, 'max_depth': 6, 'learning_rate': 0.03, 'gamma': 0.2, 'colsample_bytree': 0.8}"
      ],
      "metadata": {
        "id": "SlBoHLUZtxvd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}